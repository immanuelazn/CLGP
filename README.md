# Utilizing pre-trained genomics encoders to supplement language models
For W266 Natural Language Processing

Genomic sequences are hard to interpret and analyze, and requires specific tools to extract any useful information.  This work attempts to bridge the modality gap between biological sequences and human language, to lower the barrier to biological analysis.  Using genomics and language based encoders, contrastive pre-training was executed to develop a shared embedding projection.  These projections were used to demonstrate sequence and text retrieval with respect to a taxanomic classification. Such work implies the merit in developing future bi-modal genome language models.
